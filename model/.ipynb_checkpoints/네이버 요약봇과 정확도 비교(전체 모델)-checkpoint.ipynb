{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jungs\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import numpy as np\n",
    "import krwordrank\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "from PIL import Image\n",
    "from pykospacing import spacing\n",
    "import krwordrank\n",
    "from krwordrank.sentence import summarize_with_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리(엔터를 기준으로 한 문장으로 인식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jungs\\Anaconda3\\envs\\py36\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "noun = []\n",
    "sent = []\n",
    "for i in range(1,188):\n",
    "    data_path = 'E:\\\\news\\\\news\\\\뉴스전체\\\\뉴스_'+str(i)+'.txt'\n",
    "    def get_texts(data_path):\n",
    "        file = open(data_path, 'r',encoding='UTF-8')\n",
    "        data =file.readlines()\n",
    "        data_list = []\n",
    "        for sentence in data:\n",
    "            list_sentence1 = sentence.replace('\\n','').split('\\n')\n",
    "            for list_sentence2 in list_sentence1:\n",
    "                list_sentence = list_sentence2.replace('다.','다.  .').split('  .')\n",
    "                for lines in list_sentence:\n",
    "                    line = lines.strip()\n",
    "                    data_list.append(line)\n",
    "        texts = list(set(data_list))\n",
    "        if '' in texts:\n",
    "            texts.remove('')\n",
    "        return texts\n",
    "    texts = get_texts(data_path)\n",
    "    penalty = lambda x:0 if (25 <= len(x) <= 100) else 1\n",
    "    keywords, sents = summarize_with_sentences(\n",
    "        texts,\n",
    "        penalty=penalty,\n",
    "        stopwords={},\n",
    "        diversity=0.5,\n",
    "        num_keywords=5,\n",
    "        num_keysents=2,\n",
    "        scaling=lambda x:1,\n",
    "        verbose=False,\n",
    "        min_count = 1)\n",
    "    ex_a = \"\"\n",
    "    for s in sents:\n",
    "        ex_a += s\n",
    "    sent.append(ex_a)\n",
    "    ex_n = okt.nouns(ex_a)\n",
    "    ex_n.sort()\n",
    "    noun.append(ex_n)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_before = []\n",
    "noun_before = []\n",
    "for j in range(1,188):\n",
    "    data_path1 = 'E:\\\\news\\\\news\\\\요약전체\\\\요약_'+str(j)+'.txt'\n",
    "    def get_texts1(data_path):\n",
    "        file = open(data_path, 'r',encoding='UTF-8')\n",
    "        data =file.read()\n",
    "        return data\n",
    "    data = get_texts1(data_path1)\n",
    "    ex_aa = \"\"\n",
    "    ex_aa = data.replace(\"\\n\",'')\n",
    "    sent_before.append(ex_aa)\n",
    "    ex_bb = okt.nouns(ex_aa)\n",
    "    ex_bb.sort()\n",
    "    noun_before.append(ex_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n=1\n",
    "a=0\n",
    "a1=0\n",
    "for  i in range(0,187):\n",
    "    print(sent[i])\n",
    "    print(sent_before[i])\n",
    "    s = difflib.SequenceMatcher(lambda x: x == \" \", sent[i], sent_before[i])\n",
    "    result = round(s.ratio(), 4)\n",
    "    s1 = difflib.SequenceMatcher(lambda x: x == \" \", noun[i], noun_before[i])\n",
    "    result1 = round(s1.ratio(), 4)\n",
    "    print(\"문장 정확도는 {:0.2f}%         number:\".format(result*100)+str(n))\n",
    "    print(\"형태소 정확도는 {:0.2f}%         number:\".format(result1*100)+str(n))\n",
    "    a = a+result\n",
    "    b = (a*100)/n\n",
    "    print(\"문장 최종 정확도는\"+\"%0.2f\"%b+\"%         number:\"+str(n))\n",
    "    a1 = a1+result1\n",
    "    b1 = (a1*100)/n\n",
    "    print(\"형태소 최종 정확도는\"+\"%0.2f\"%b1+\"%         number:\"+str(n))\n",
    "    n = n+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
