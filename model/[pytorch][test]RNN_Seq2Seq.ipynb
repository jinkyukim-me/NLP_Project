{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RNN_Seq2Seq.ipynb","provenance":[],"collapsed_sections":[]},"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.449695Z","start_time":"2019-09-25T10:45:57.966254Z"},"colab_type":"code","id":"6wxXfDAOAt4w","colab":{}},"source":["import random\n","import torch\n","import torch.nn as nn\n","from torch import optim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.590641Z","start_time":"2019-09-25T10:45:58.452479Z"},"id":"X0QTlZkICf0Z","colab_type":"code","colab":{}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.613545Z","start_time":"2019-09-25T10:45:58.593614Z"},"colab_type":"code","id":"R5KqdIobAt40","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1410227a-d90b-4c91-981e-5aaf7b61d95c","executionInfo":{"status":"ok","timestamp":1569409268224,"user_tz":-540,"elapsed":1498,"user":{"displayName":"Jinkyu Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBI3V4v2jgGjDWZ9LguiZGukfMnweTODPPC0mGktMA=s64","userId":"17799218152297571837"}}},"source":["torch.manual_seed(0)\n","#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f6e3091fbb0>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.620528Z","start_time":"2019-09-25T10:45:58.615543Z"},"colab_type":"code","id":"uaDFU2NkAt43","colab":{}},"source":["raw = [\"I feel hungry.\t나는 배가 고프다.\",\n","       \"Pytorch is very easy.\t파이토치는 매우 쉽다.\",\n","       \"Pytorch is a framework for deep learning.\t파이토치는 딥러닝을 위한 프레임워크이다.\",\n","       \"Pytorch is very clear to use.\t파이토치는 사용하기 매우 직관적이다.\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.630535Z","start_time":"2019-09-25T10:45:58.622522Z"},"colab_type":"code","id":"eeBTfj7wAt47","colab":{}},"source":["# fix token for \"start of sentence\" and \"end of sentence\"\n","SOS_token = 0\n","EOS_token = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.643477Z","start_time":"2019-09-25T10:45:58.632497Z"},"colab_type":"code","id":"--6v4wcpAt4-","colab":{}},"source":["# class for vocabulary related information of data\n","class Vocab:\n","    def __init__(self):\n","        self.vocab2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token}\n","        self.index2vocab = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n","        self.vocab_count = {}\n","        self.n_vocab = len(self.vocab2index)\n","\n","    def add_vocab(self, sentence):\n","        for word in sentence.split(\" \"):\n","            if word not in self.vocab2index:\n","                self.vocab2index[word] = self.n_vocab\n","                self.vocab_count[word] = 1\n","                self.index2vocab[self.n_vocab] = word\n","                self.n_vocab += 1\n","            else:\n","                self.vocab_count[word] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.657463Z","start_time":"2019-09-25T10:45:58.648453Z"},"colab_type":"code","id":"X_jG6lZ-At5B","colab":{}},"source":["# filter out the long sentence from source and target data\n","def filter_pair(pair, source_max_length, target_max_length):\n","    return len(pair[0].split(\" \")) < source_max_length and len(pair[1].split(\" \")) < target_max_length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.670395Z","start_time":"2019-09-25T10:45:58.660422Z"},"colab_type":"code","id":"ZIAnNXVxAt5E","colab":{}},"source":["# read and preprocess the corpus data\n","def preprocess(corpus, source_max_length, target_max_length):\n","    print(\"reading corpus...\")\n","    pairs = []\n","    for line in corpus:\n","        pairs.append([s for s in line.strip().lower().split(\"\\t\")])\n","    print(\"Read {} sentence pairs\".format(len(pairs)))\n","\n","    pairs = [pair for pair in pairs if filter_pair(pair, source_max_length, target_max_length)]\n","    print(\"Trimmed to {} sentence pairs\".format(len(pairs)))\n","\n","    source_vocab = Vocab()\n","    target_vocab = Vocab()\n","\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        source_vocab.add_vocab(pair[0])\n","        target_vocab.add_vocab(pair[1])\n","    print(\"source vocab size =\", source_vocab.n_vocab)\n","    print(\"target vocab size =\", target_vocab.n_vocab)\n","\n","    return pairs, source_vocab, target_vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.682363Z","start_time":"2019-09-25T10:45:58.672396Z"},"colab_type":"code","id":"HCrd96clAt5H","colab":{}},"source":["# declare simple encoder\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        return x, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.694347Z","start_time":"2019-09-25T10:45:58.686351Z"},"colab_type":"code","id":"8lHR9muMAt5K","colab":{}},"source":["# declare simple decoder\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        x = self.softmax(self.out(x[0]))\n","        return x, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.707326Z","start_time":"2019-09-25T10:45:58.697324Z"},"colab_type":"code","id":"Cu_Qe5xOAt5M","colab":{}},"source":["# convert sentence to the index tensor\n","# sentence -> one hot vector\n","def tensorize(vocab, sentence):\n","    indexes = [vocab.vocab2index[word] for word in sentence.split(\" \")]\n","    indexes.append(vocab.vocab2index[\"<EOS>\"])\n","    return torch.Tensor(indexes).long().to(device).view(-1, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.726246Z","start_time":"2019-09-25T10:45:58.709292Z"},"colab_type":"code","id":"XsAbQd1RAt5P","colab":{}},"source":["# training seq2seq\n","def train(pairs, source_vocab, target_vocab, encoder, decoder, n_iter, print_every=1000, learning_rate=0.01):\n","    loss_total = 0\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    training_batch = [random.choice(pairs) for _ in range(n_iter)]\n","    training_source = [tensorize(source_vocab, pair[0]) for pair in training_batch]\n","    training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n","\n","    criterion = nn.NLLLoss()\n","\n","    for i in range(1, n_iter + 1):\n","        source_tensor = training_source[i - 1]\n","        target_tensor = training_target[i - 1]\n","\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","\n","        source_length = source_tensor.size(0)\n","        target_length = target_tensor.size(0)\n","\n","        loss = 0\n","\n","        for enc_input in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n","\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden # connect encoder output to decoder input\n","\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # teacher forcing\n","\n","        loss.backward()\n","\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","        loss_iter = loss.item() / target_length\n","        loss_total += loss_iter\n","\n","        if i % print_every == 0:\n","            loss_avg = loss_total / print_every\n","            loss_total = 0\n","            print(\"[{} - {}%] loss = {:05.4f}\".format(i, i / n_iter * 100, loss_avg))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.739220Z","start_time":"2019-09-25T10:45:58.730234Z"},"colab_type":"code","id":"BblYJOiWAt5T","colab":{}},"source":["# insert given sentence to check the training\n","def evaluate(pairs, source_vocab, target_vocab, encoder, decoder, target_max_length):\n","    for pair in pairs:\n","        print(\">\", pair[0])\n","        print(\"=\", pair[1])\n","        source_tensor = tensorize(source_vocab, pair[0])\n","        source_length = source_tensor.size()[0]\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        for ei in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[ei], encoder_hidden)\n","\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden\n","        decoded_words = []\n","\n","        for di in range(target_max_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            _, top_index = decoder_output.data.topk(1)\n","            if top_index.item() == EOS_token:\n","                decoded_words.append(\"<EOS>\")\n","                break\n","            else:\n","                decoded_words.append(target_vocab.index2vocab[top_index.item()])\n","\n","            decoder_input = top_index.squeeze().detach()\n","\n","        predict_words = decoded_words\n","        predict_sentence = \" \".join(predict_words)\n","        print(\"<\", predict_sentence)\n","        print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.752208Z","start_time":"2019-09-25T10:45:58.742203Z"},"colab_type":"code","id":"0302Eu1aAt5Y","colab":{}},"source":["# declare max length for sentence\n","SOURCE_MAX_LENGTH = 10\n","TARGET_MAX_LENGTH = 12"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:45:58.780130Z","start_time":"2019-09-25T10:45:58.755168Z"},"colab_type":"code","executionInfo":{"status":"ok","timestamp":1569409268230,"user_tz":-540,"elapsed":1312,"user":{"displayName":"Jinkyu Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBI3V4v2jgGjDWZ9LguiZGukfMnweTODPPC0mGktMA=s64","userId":"17799218152297571837"}},"id":"E9qI1OZDAt5b","outputId":"0101ebb6-01a0-4006-ada1-beb854b596a1","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# preprocess the corpus\n","load_pairs, load_source_vocab, load_target_vocab = preprocess(raw, SOURCE_MAX_LENGTH, TARGET_MAX_LENGTH)\n","print(random.choice(load_pairs))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["reading corpus...\n","Read 4 sentence pairs\n","Trimmed to 4 sentence pairs\n","Counting words...\n","source vocab size = 17\n","target vocab size = 13\n","['pytorch is very easy.', '파이토치는 매우 쉽다.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:46:01.642148Z","start_time":"2019-09-25T10:45:58.782095Z"},"colab_type":"code","id":"Jeh8UhWmAt5g","colab":{}},"source":["# declare the encoder and the decoder\n","enc_hidden_size = 16\n","dec_hidden_size = enc_hidden_size\n","enc = Encoder(load_source_vocab.n_vocab, enc_hidden_size).to(device)\n","dec = Decoder(dec_hidden_size, load_target_vocab.n_vocab).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:47:37.239461Z","start_time":"2019-09-25T10:46:01.643149Z"},"colab_type":"code","executionInfo":{"status":"ok","timestamp":1569409325220,"user_tz":-540,"elapsed":58278,"user":{"displayName":"Jinkyu Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBI3V4v2jgGjDWZ9LguiZGukfMnweTODPPC0mGktMA=s64","userId":"17799218152297571837"}},"id":"uahx2fREAt5l","outputId":"4ec233ae-f549-40c0-e5d1-b75d178c07b0","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# train seq2seq model\n","train(load_pairs, load_source_vocab, load_target_vocab, enc, dec, 5000, print_every=1000)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[1000 - 20.0%] loss = 0.7387\n","[2000 - 40.0%] loss = 0.1080\n","[3000 - 60.0%] loss = 0.0341\n","[4000 - 80.0%] loss = 0.0183\n","[5000 - 100.0%] loss = 0.0126\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-09-25T10:47:37.434948Z","start_time":"2019-09-25T10:47:37.243424Z"},"colab_type":"code","executionInfo":{"status":"ok","timestamp":1569409325225,"user_tz":-540,"elapsed":58274,"user":{"displayName":"Jinkyu Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBI3V4v2jgGjDWZ9LguiZGukfMnweTODPPC0mGktMA=s64","userId":"17799218152297571837"}},"id":"-D4aPyf0At5q","outputId":"daefcedc-e38d-4b9c-aa35-9a1ee7b9854e","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# check the model with given data\n","evaluate(load_pairs, load_source_vocab, load_target_vocab, enc, dec, TARGET_MAX_LENGTH)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["> i feel hungry.\n","= 나는 배가 고프다.\n","< 나는 배가 고프다. <EOS>\n","\n","> pytorch is very easy.\n","= 파이토치는 매우 쉽다.\n","< 파이토치는 매우 쉽다. <EOS>\n","\n","> pytorch is a framework for deep learning.\n","= 파이토치는 딥러닝을 위한 프레임워크이다.\n","< 파이토치는 딥러닝을 위한 프레임워크이다. <EOS>\n","\n","> pytorch is very clear to use.\n","= 파이토치는 사용하기 매우 직관적이다.\n","< 파이토치는 사용하기 매우 직관적이다. <EOS>\n","\n"],"name":"stdout"}]}]}